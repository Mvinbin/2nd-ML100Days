{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.5.3\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for 'caret' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called 'codetools'\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for 'caret' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called 'codetools'\nTraceback:\n",
      "1. library(caret)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "#觀察範例，在房價預測中調整標籤編碼(Label Encoder) / 獨熱編碼 (One Hot Encoder) 方式，\n",
    "#對於線性迴歸以及梯度提升樹兩種模型，何者影響比較大?\n",
    "library(dplyr)\n",
    "library(magrittr)\n",
    "library(caret)\n",
    "train=read.csv('C:\\\\Users\\\\coco40725\\\\Documents\\\\GitHub\\\\2nd-ML100Days\\\\data\\\\house.train.csv',sep=',',header=T)\n",
    "test=read.csv('C:\\\\Users\\\\coco40725\\\\Documents\\\\GitHub\\\\2nd-ML100Days\\\\data\\\\house.test.csv',sep=',',header=T)\n",
    "\n",
    "##extract categorical variable\n",
    "col.type=rep(0,81)\n",
    "for (i in 1:81) {\n",
    "  col.type[i]=class(train[,i])\n",
    "}\n",
    "col.factor=which(col.type=='factor')\n",
    "\n",
    "\n",
    "##only keep categorical column\n",
    "train.cate=train[,c(col.factor,81)]\n",
    "test.cate=test[,col.factor]\n",
    "\n",
    "## covert NA into a level\n",
    "for (j in 1:43) {\n",
    "  train.cate[,j] %<>% addNA(.)\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "## linear regression+ lable coding\n",
    "train.cate.label=train.cate\n",
    "for (k in 1:43) {\n",
    "  train.cate.label[,k] %<>% as.numeric(.)\n",
    "}\n",
    "t11=Sys.time()\n",
    "train_control <- trainControl(method=\"cv\", number=5)\n",
    "cv1= train(SalePrice~., data=train.cate.label, trControl=train_control, method=\"lm\")\n",
    "t12=Sys.time()\n",
    "time1=difftime(t11,t12,units='secs')\n",
    "rmse1=cv1$results[2]\n",
    "rsq1=cv1$results[3]\n",
    "fit1=lm(SalePrice~.,data=train.cate.label)\n",
    "summary(fit1)\n",
    "\n",
    "\n",
    "\n",
    "## linear regression + one hot coding\n",
    "\n",
    "train_control <- trainControl(method=\"cv\", number=5)\n",
    "t11=Sys.time()\n",
    "cv2= train(SalePrice~., data=train.cate, trControl=train_control, method=\"lm\")\n",
    "t12=Sys.time()\n",
    "\n",
    "time2=difftime(t11,t12,units='secs')\n",
    "rmse2=cv2$results[2]\n",
    "rsq2=cv2$results[3]\n",
    "fit2=lm(SalePrice~.,data=train.cate)\n",
    "summary(fit2)\n",
    "\n",
    "\n",
    "library(xgboost)\n",
    "library(dummies)\n",
    "\n",
    "## gboost + lable coding\n",
    "t11=Sys.time()\n",
    "xgb.fit1 <- xgb.cv(\n",
    "  data = as.matrix(train.cate.label[,-44]),\n",
    "  label = train.cate.label[,44],\n",
    "  nrounds = 100,\n",
    "  nfold = 5,\n",
    "  objective = \"reg:linear\",  # for regression models\n",
    "  verbose = 0               # silent,不要顯示詳細資訊\n",
    ")\n",
    "t12=Sys.time()\n",
    "gb.mse1=mean(unlist(xgb.fit1$evaluation_log[,4]))\n",
    "time.gb1=difftime(t11,t12,units='secs')\n",
    "\n",
    "## gboost + one hot coding\n",
    "train.dummy=train.cate[,44]\n",
    "for (p in 1:43) {\n",
    "  train.dummy=cbind(train.dummy,dummy(train.cate[,p]))\n",
    "}\n",
    "\n",
    "t11=Sys.time()\n",
    "xgb.fit2 <- xgb.cv(\n",
    "  data = as.matrix(train.dummy[,-1]),\n",
    "  label = train.dummy[,1],\n",
    "  nrounds = 100,\n",
    "  nfold = 5,\n",
    "  objective = \"reg:linear\",  # for regression models\n",
    "  verbose = 0               # silent,不要顯示詳細資訊\n",
    ")\n",
    "\n",
    "t12=Sys.time()\n",
    "gb.mse2=mean(unlist(xgb.fit2$evaluation_log[,4]))\n",
    "time.gb2=difftime(t11,t12,units='secs')\n",
    "\n",
    "######## 解析\n",
    "\n",
    "regression.mse.diff=rmse2-rmse1\n",
    "regression.mse.diff\n",
    "regression.rsq.diff=rsq2-rsq1\n",
    "regression.rsq.diff\n",
    "xgb.mse.diff=gb.mse2-gb.mse1\n",
    "xgb.mse.diff\n",
    "\n",
    "regression.time.diff=time2-time1\n",
    "regression.time.diff\n",
    "xgb.time.diff=time.gb2-time.gb1\n",
    "xgb.time.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression and xgboost has better performance when we carry out  one hot coding. However, it is obvious that we need to spend much time calculating cv results, since one hot coding increase a lot of dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.5.3\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for 'caret' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called 'codetools'\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for 'caret' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n there is no package called 'codetools'\nTraceback:\n",
      "1. library(caret)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(magrittr)\n",
    "library(caret)\n",
    "#鐵達尼號例題中，標籤編碼 / 獨熱編碼又分別對預測結果有何影響? (Hint : 參考今日範例)\n",
    "#鐵達尼號例題中，標籤編碼 / 獨熱編碼又分別對預測結果有何影響? (Hint : 參考今日範例)\n",
    "train=read.csv('C:\\\\Users\\\\coco40725\\\\Documents\\\\GitHub\\\\2nd-ML100Days\\\\data\\\\titanic_train.csv')\n",
    "train=train[,-c(1,4,9)]\n",
    "\n",
    "##extract categorical variable\n",
    "col.type=rep(0,9)\n",
    "for (i in 1:9) {\n",
    "  col.type[i]=class(train[,i])\n",
    "}\n",
    "col.factor=which(col.type=='factor')\n",
    "\n",
    "\n",
    "\n",
    "##only keep categorical column\n",
    "train.cate=train[,c(col.factor,1)]\n",
    "\n",
    "## covert NA into a level\n",
    "for (j in 1:3) {\n",
    "  train.cate[,j] %<>% addNA(.)\n",
    "  \n",
    "}\n",
    "\n",
    "## linear regression+ lable coding\n",
    "train.cate.label=train.cate\n",
    "for (k in 1:3) {\n",
    "  train.cate.label[,k] %<>% as.numeric(.)\n",
    "}\n",
    "\n",
    "\n",
    "t11=Sys.time()\n",
    "train_control <- trainControl(method=\"cv\", number=5)\n",
    "cv1= train(as.factor(Survived)~., data=train.cate.label, family=binomial,trControl=train_control, method=\"glm\")\n",
    "t12=Sys.time()\n",
    "time1=difftime(t11,t12,units='secs')\n",
    "racc1=cv1$results[2]\n",
    "rkappa1=cv1$results[3]\n",
    "\n",
    "\n",
    "## linear regression + one hot coding\n",
    "## gboost + one hot coding\n",
    "\n",
    "\n",
    "train_control <- trainControl(method=\"cv\", number=5)\n",
    "t11=Sys.time()\n",
    "cv2= train(as.factor(Survived)~., data=train.cate, family=binomial,trControl=train_control, method=\"glm\")\n",
    "t12=Sys.time()\n",
    "\n",
    "time2=difftime(t11,t12,units='secs')\n",
    "racc2=cv2$results[2]\n",
    "rkappa2=cv2$results[3]\n",
    "summary(fit2)\n",
    "\n",
    "\n",
    "library(xgboost)\n",
    "library(dummies)\n",
    "\n",
    "## gboost + lable coding\n",
    "t11=Sys.time()\n",
    "xgb.fit1 <- xgb.cv(\n",
    "  data = as.matrix(train.cate.label[,-4]),\n",
    "  label = train.cate.label[,4],\n",
    "  nrounds = 100,\n",
    "  nfold = 5,\n",
    "  objective = \"reg:logistic\",  # for regression models\n",
    "  verbose = 0               # silent,不要顯示詳細資訊\n",
    ")\n",
    "t12=Sys.time()\n",
    "gb.mse1=mean(unlist(xgb.fit1$evaluation_log[,4]))\n",
    "time.gb1=difftime(t11,t12,units='secs')\n",
    "\n",
    "\n",
    "## gboost + one hot coding\n",
    "train.dummy=train.cate[,4]\n",
    "for (p in 1:3) {\n",
    "  train.dummy=cbind(train.dummy,dummy(train.cate[,p]))\n",
    "}\n",
    "\n",
    "t11=Sys.time()\n",
    "xgb.fit2 <- xgb.cv(\n",
    "  data = as.matrix(train.dummy[,-1]),\n",
    "  label = train.dummy[,1],\n",
    "  nrounds = 100,\n",
    "  nfold = 5,\n",
    "  objective = \"reg:logistic\",  # for regression models\n",
    "  verbose = 0               # silent,不要顯示詳細資訊\n",
    ")\n",
    "\n",
    "t12=Sys.time()\n",
    "gb.mse2=mean(unlist(xgb.fit2$evaluation_log[,4]))\n",
    "time.gb2=difftime(t11,t12,units='secs')\n",
    "\n",
    "######## 解析\n",
    "\n",
    "regression.acc.diff=racc2-racc1\n",
    "regression.acc.diff\n",
    "regression.kappa.diff=rkappa2-rkappa1\n",
    "regression.kappa.diff\n",
    "xgb.mse.diff=gb.mse2-gb.mse1\n",
    "xgb.mse.diff\n",
    "\n",
    "regression.time.diff=time2-time1\n",
    "regression.time.diff\n",
    "xgb.time.diff=time.gb2-time.gb1\n",
    "xgb.time.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In titanic data which is a calssification problem,  logistic and xgboost still have better performance in one hot coding, and still, one hot coding is more time consumming than label coding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
