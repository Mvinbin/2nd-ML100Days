{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(tensorflow): there is no package called 'tensorflow'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(tensorflow): there is no package called 'tensorflow'\nTraceback:\n",
      "1. library(tensorflow)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(tensorflow)\n",
    "library(keras)\n",
    "library(devtools)\n",
    "library(xgboost)\n",
    "data<-dataset_mnist()\n",
    "\n",
    "#Training Data\n",
    "train_x<-data$train$x\n",
    "train_y<-data$train$y\n",
    "\n",
    "#Test Data\n",
    "test_x<-data$test$x\n",
    "test_y<-data$test$y\n",
    "\n",
    "#converting a 2D array into a 1D array for feeding \n",
    "#into the MLP and normalising the matrix\n",
    "train_x <- array(as.numeric(train_x), dim = c(dim(train_x)[[1]], 28*28))\n",
    "test_x <- array(as.numeric(test_x), dim = c(dim(test_x)[[1]], 28*28))\n",
    "train_x <- train_x / 255\n",
    "test_x <- test_x / 255\n",
    "\n",
    "\n",
    "\n",
    "fit=xgboost(data=train_x,label=train_y,\n",
    "            nrounds=5,\n",
    "            objective=\"multi:softprob\",\n",
    "            num_class =10)\n",
    "\n",
    "pred=matrix(predict(fit,test_x),ncol=10)\n",
    "pred.new=rep(0,nrow(pred))\n",
    "for (i in 1:nrow(pred)) {\n",
    "  pred.new[i]= which.max(pred[i,])\n",
    "}\n",
    "pred.new=pred.new-1\n",
    "\n",
    "sum(diag(table(pred.new,test_y)))/nrow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
